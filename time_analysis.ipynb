{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "\n",
    "INPUT_DATA = '../data/sf-bay-area-bike-share/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station_id,bikes_available,docks_available,time\r\n",
      "2,2,25,2013/08/29 12:06:01\r\n",
      "2,2,25,2013/08/29 12:07:01\r\n",
      "2,2,25,2013/08/29 12:08:01\r\n",
      "2,2,25,2013/08/29 12:09:01\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 {INPUT_DATA}status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,name,lat,long,dock_count,city,installation_date\r\n",
      "2,San Jose Diridon Caltrain Station,37.329732,-121.90178200000001,27,San Jose,8/6/2013\r\n",
      "3,San Jose Civic Center,37.330698,-121.888979,15,San Jose,8/5/2013\r\n",
      "4,Santa Clara at Almaden,37.333988,-121.894902,11,San Jose,8/6/2013\r\n",
      "5,Adobe on Almaden,37.331415,-121.8932,19,San Jose,8/5/2013\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 {INPUT_DATA}station.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_status = sc.textFile(INPUT_DATA + 'status.csv').cache()\n",
    "header = bike_status.first()\n",
    "bike_status = bike_status.filter(lambda x: x != header).map(lambda x: x.split(',')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71984434"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2013, 8, 29, 12, 6, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ts = bike_status.take(1)[-1][-1]\n",
    "dt = datetime.strptime(test_ts, \"%Y/%m/%d %H:%M:%S\")\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toIntSafe(num):\n",
    "    try:\n",
    "        return int(num)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "def toFloatSafe(num):\n",
    "    try:\n",
    "        return float(num)\n",
    "    except ValueError:\n",
    "        return None    \n",
    "    \n",
    "def toTimeStampSafe(data):\n",
    "    try:\n",
    "        return datetime.strptime(data, \"%Y/%m/%d %H:%M:%S\") \n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "def convertData(data):\n",
    "    return (toIntSafe(data[0]),\n",
    "            toIntSafe(data[1]),\n",
    "            toIntSafe(data[2]),\n",
    "            toTimeStampSafe(data[3]))\n",
    "\n",
    "def preprocess_data(data):\n",
    "    try:\n",
    "        return (data[0], (data[2]*1.0)/(data[1] + data[2]), data[3].year,\n",
    "            data[3].month, data[3].day, data[3].hour, data[3].minute, data[3].isoweekday())\n",
    "    except (AttributeError, ValueError, ZeroDivisionError):\n",
    "        return None\n",
    "\n",
    "bike_status_processed = bike_status.map(lambda x:\n",
    "                                        convertData(x)).map(lambda x:preprocess_data(x)).filter(lambda x: x != None).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16994602"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_processed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[3] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.9259259259259259, 2013, 8, 29, 12, 6, 4),\n",
       " (2, 0.9259259259259259, 2013, 8, 29, 12, 7, 4),\n",
       " (2, 0.9259259259259259, 2013, 8, 29, 12, 8, 4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_processed.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_status_schema = StructType([StructField('station_id', IntegerType(),False),\n",
    "                                StructField('bikes_utilised_percentage', FloatType(),False),\n",
    "                                StructField('year', IntegerType(), False),\n",
    "                                StructField('month', IntegerType(), False),\n",
    "                                StructField('day', IntegerType(), False),\n",
    "                                StructField('hour', IntegerType(), False),\n",
    "                                StructField('minute', IntegerType(), False),\n",
    "                                StructField('day_of_week', IntegerType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------------+----+-----+---+----+------+-----------+\n",
      "|station_id|bikes_utilised_percentage|year|month|day|hour|minute|day_of_week|\n",
      "+----------+-------------------------+----+-----+---+----+------+-----------+\n",
      "|         2|                0.9259259|2013|    8| 29|  12|     6|          4|\n",
      "|         2|                0.9259259|2013|    8| 29|  12|     7|          4|\n",
      "|         2|                0.9259259|2013|    8| 29|  12|     8|          4|\n",
      "|         2|                0.9259259|2013|    8| 29|  12|     9|          4|\n",
      "|         2|                0.9259259|2013|    8| 29|  12|    10|          4|\n",
      "+----------+-------------------------+----+-----+---+----+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bike_status_df = sqlContext.createDataFrame(bike_status_processed, bike_status_schema).cache()\n",
    "bike_status_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16994602"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: integer (nullable = false)\n",
      " |-- bikes_utilised_percentage: float (nullable = false)\n",
      " |-- year: integer (nullable = false)\n",
      " |-- month: integer (nullable = false)\n",
      " |-- day: integer (nullable = false)\n",
      " |-- hour: integer (nullable = false)\n",
      " |-- minute: integer (nullable = false)\n",
      " |-- day_of_week: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bike_status_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[6] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_processed.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(day_of_week=1),\n",
       " Row(day_of_week=6),\n",
       " Row(day_of_week=3),\n",
       " Row(day_of_week=5),\n",
       " Row(day_of_week=4),\n",
       " Row(day_of_week=7),\n",
       " Row(day_of_week=2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_df.select('day_of_week').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hour=12),\n",
       " Row(hour=22),\n",
       " Row(hour=1),\n",
       " Row(hour=13),\n",
       " Row(hour=16),\n",
       " Row(hour=6),\n",
       " Row(hour=3),\n",
       " Row(hour=20),\n",
       " Row(hour=5),\n",
       " Row(hour=19),\n",
       " Row(hour=15),\n",
       " Row(hour=17),\n",
       " Row(hour=9),\n",
       " Row(hour=4),\n",
       " Row(hour=8),\n",
       " Row(hour=23),\n",
       " Row(hour=7),\n",
       " Row(hour=10),\n",
       " Row(hour=21),\n",
       " Row(hour=11),\n",
       " Row(hour=14),\n",
       " Row(hour=2),\n",
       " Row(hour=0),\n",
       " Row(hour=18)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_df.select('hour').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------------+----+-----+---+----+------+-----------+---------+---------+\n",
      "|station_id|bikes_utilised_percentage|year|month|day|hour|minute|day_of_week| day_part|isWeekday|\n",
      "+----------+-------------------------+----+-----+---+----+------+-----------+---------+---------+\n",
      "|         2|                0.9259259|2013|    8| 29|  12|     6|          4|afternoon|        1|\n",
      "|         2|                0.9259259|2013|    8| 29|  12|     7|          4|afternoon|        1|\n",
      "|         2|                0.9259259|2013|    8| 29|  12|     8|          4|afternoon|        1|\n",
      "|         2|                0.9259259|2013|    8| 29|  12|     9|          4|afternoon|        1|\n",
      "|         2|                0.9259259|2013|    8| 29|  12|    10|          4|afternoon|        1|\n",
      "+----------+-------------------------+----+-----+---+----+------+-----------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "bike_status_period = bike_status_df.withColumn('day_part',\n",
    "                                               F.when((bike_status_df[\"hour\"] >= 20) | (bike_status_df[\"hour\"] < 6), 'night').\\\n",
    "                                               when((bike_status_df[\"hour\"] >= 6) & (bike_status_df[\"hour\"] < 12), 'morning').\\\n",
    "                                               when((bike_status_df[\"hour\"] >= 12) & (bike_status_df[\"hour\"] < 16), 'afternoon').\\\n",
    "                                               otherwise('evening'))\n",
    "\n",
    "bike_status_period = bike_status_period.withColumn('isWeekday',\n",
    "                                                   F.when(bike_status_period[\"day_of_week\"] <= 5, 1).otherwise(0)).cache()\n",
    "bike_status_period.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(day_part=u'afternoon'),\n",
       " Row(day_part=u'night'),\n",
       " Row(day_part=u'morning'),\n",
       " Row(day_part=u'evening')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_period.select('day_part').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16994602"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_period.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16994602"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_period = bike_status_period.drop('year', 'hour', 'minute', 'day', 'isWeekday').cache()\n",
    "bike_status_period.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+-----------+------------------------------+\n",
      "|station_id|month|day_part|day_of_week|avg(bikes_utilised_percentage)|\n",
      "+----------+-----+--------+-----------+------------------------------+\n",
      "|         5|   10| evening|          4|            0.5196670549274289|\n",
      "|         6|   12| morning|          6|            0.6242195955995057|\n",
      "|         7|    9| morning|          1|            0.5324195619312885|\n",
      "|         8|   12| morning|          2|           0.44103705240620505|\n",
      "|        10|    9| morning|          6|            0.5929139699094639|\n",
      "+----------+-----+--------+-----------+------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bike_status_final = bike_status_period.groupBy('station_id', 'month', 'day_part', 'day_of_week').mean('bikes_utilised_percentage')\n",
    "bike_status_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11720"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_status_final = bike_status_final.withColumnRenamed('avg(bikes_utilised_percentage)', 'avg_util_perc')\n",
    "bike_status_final.cache()\n",
    "bike_status_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_avg = bike_status_period.select('station_id', 'day_part', 'isWeekday', 'bikes_utilised_percentage').\\\n",
    "#                                    groupBy('station_id', 'day_part', 'isWeekday').\\\n",
    "#     mean('bikes_utilised_percentage').cache()\n",
    "\n",
    "# daily_avg.show(5)\n",
    "# daily_avg = daily_avg.withColumnRenamed('avg(bikes_utilised_percentage)', 'avg_bike_util')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station = sc.textFile(INPUT_DATA + 'station.csv')\n",
    "# header = station.first()\n",
    "# station = station.filter(lambda x: x != header).map(lambda x: x.split(',')).map(lambda x:\n",
    "#                                                                                 (int(x[0]), float(x[2]),\n",
    "#                                                                                  float(x[3]), x[5]))\n",
    "\n",
    "# station_schema = StructType([StructField('station_id', IntegerType(), False),\n",
    "#                             StructField('latitude', DoubleType(), False),\n",
    "#                             StructField('longitude', DoubleType(), False),\n",
    "#                             StructField('city', StringType(), False),])\n",
    "\n",
    "# station_df = sqlContext.createDataFrame(station, station_schema)\n",
    "\n",
    "# df_daily_avg = daily_avg.join(station_df, on='station_id')\n",
    "# df_daily_avg.show(5)\n",
    "\n",
    "# df_daily_avg.toPandas().to_csv(INPUT_DATA + 'daily_avg_with_city.csv', index = False)\n",
    "\n",
    "# !head {INPUT_DATA}daily_avg_with_city.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "def implement_string_indexer(cols, df):\n",
    "    for c in cols:\n",
    "        si = StringIndexer(inputCol=c, outputCol=c+'_si')\n",
    "        sm = si.fit(df)\n",
    "        df = sm.transform(df).drop(c)\n",
    "        df = df.withColumnRenamed(c + '_si', c)\n",
    "        return df\n",
    "\n",
    "cols = ['day_part']\n",
    "\n",
    "final_df = implement_string_indexer(cols, bike_status_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----------+-------------------+--------+\n",
      "|station_id|month|day_of_week|      avg_util_perc|day_part|\n",
      "+----------+-----+-----------+-------------------+--------+\n",
      "|         5|   10|          4| 0.5196670549274289|     2.0|\n",
      "|         6|   12|          6| 0.6242195955995057|     3.0|\n",
      "|         7|    9|          1| 0.5324195619312885|     3.0|\n",
      "|         8|   12|          2|0.44103705240620505|     3.0|\n",
      "|        10|    9|          6| 0.5929139699094639|     3.0|\n",
      "+----------+-----+-----------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.cache()\n",
    "final_df.count()\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[5.0,0.5196670549...|\n",
      "|[6.0,0.6242195955...|\n",
      "|[7.0,0.5324195619...|\n",
      "|[8.0,0.4410370524...|\n",
      "|[10.0,0.592913969...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_cols = ['station_id', 'avg_util_perc', 'month', \n",
    "              'day_of_week', 'day_part']\n",
    "\n",
    "va = VectorAssembler(inputCols= input_cols, outputCol= 'features')\n",
    "df_transformed = va.transform(final_df).select('features')\n",
    "df_transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11720"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.cache()\n",
    "df_transformed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wssse = 1e10\n",
    "\n",
    "for clusters in range(2,6):\n",
    "\n",
    "    # Trains a k-means model.\n",
    "    kmeans = KMeans().setK(clusters).setSeed(1)\n",
    "    model = kmeans.fit(df_transformed)\n",
    "\n",
    "    # Evaluate clustering by computing Within Set Sum of Squared Errors.\n",
    "    wssse = model.computeCost(df_transformed)\n",
    "    if wssse <= min_wssse:\n",
    "        min_wssse = wssse\n",
    "        best_n_clusters = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Within Set Sum of Squared Errors = 485012.12266\n",
      "Best number of clusters = 5\n",
      "Cluster Centers: \n",
      "[ 28.22810358   0.48059937   7.28712871   4.05788271   1.49200305]\n",
      "[ 72.63795551   0.52525977   7.14623758   4.05868434   1.4921912 ]\n",
      "[ 8.57142857  0.49021524  7.53072626  4.06703911  1.49162011]\n",
      "[ 60.           0.5406415    7.53072626   4.06703911   1.49162011]\n",
      "[ 44.41666667   0.516114     7.53072626   4.06703911   1.49162011]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Within Set Sum of Squared Errors = \" + str(min_wssse))\n",
    "print(\"Best number of clusters = \" + str(best_n_clusters))\n",
    "\n",
    "kmeans = KMeans().setK(best_n_clusters).setSeed(1)\n",
    "model = kmeans.fit(df_transformed)\n",
    "\n",
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
